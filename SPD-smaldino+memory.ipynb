{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "attached-coral",
   "metadata": {
    "id": "cellular-identity"
   },
   "source": [
    "# SPD\n",
    "\n",
    "Replicate the design of [Smaldino et al. (2013)](https://www.journals.uchicago.edu/doi/10.1086/669615).\n",
    "\n",
    "Add per-agent memory. Remember defectors. Vary memory size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-current",
   "metadata": {
    "id": "homeless-petroleum"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-migration",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lucky-miracle",
    "outputId": "9d9a3cf1-ac30-4bcb-ecda-c38e236e001c"
   },
   "outputs": [],
   "source": [
    "# model\n",
    "from mesa_fork import Model, Agent\n",
    "from mesa_fork.time import RandomActivation\n",
    "from mesa_fork.space import SingleGrid\n",
    "from mesa_fork.datacollection import DataCollector\n",
    "from enum import Enum\n",
    "\n",
    "# visualization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('axes', labelsize=8)\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "import holoviews as hv\n",
    "%load_ext holoviews.ipython\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "from my_plot import my_plot_export\n",
    "\n",
    "# parameter sweep\n",
    "from mesa_fork.batchrunner import BatchRunnerMP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-russell",
   "metadata": {
    "id": "common-allah"
   },
   "source": [
    "## Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    \"\"\"\n",
    "    Fixed-size FIFO (first-in-first-out) memory.\n",
    "    Used by agents to remeber the most recent defectors.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 size):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            size: memory size\n",
    "        \"\"\"\n",
    "        \n",
    "        self.size = size\n",
    "        self.memory = []\n",
    "        \n",
    "        \n",
    "    def add(self, item):\n",
    "        \n",
    "        # remove duplicates\n",
    "        self.memory[:] = list(filter(\n",
    "            lambda x: x != item,\n",
    "            self.memory))\n",
    "        \n",
    "        self.memory.insert(0, item)\n",
    "        \n",
    "        # truncate to size\n",
    "        while len(self.memory) > self.size:\n",
    "            self.memory.pop(-1)\n",
    "       \n",
    "    \n",
    "    def contains(self, item):\n",
    "        try:\n",
    "            self.memory.index(item)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-adelaide",
   "metadata": {
    "id": "retained-albuquerque"
   },
   "outputs": [],
   "source": [
    "class Action(Enum):\n",
    "    COOPERATE = 1\n",
    "    DEFECT    = 2\n",
    "\n",
    "    \n",
    "class SmaldinoAgentWithMemory(Agent):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model,\n",
    "                 energy,\n",
    "                 max_energy,\n",
    "                 memory_size,\n",
    "                 cooperator=False):\n",
    "        \n",
    "        super().__init__(model.next_id(), model)\n",
    "        \n",
    "        self.memory = Memory(memory_size)\n",
    "        \n",
    "        self.energy = energy\n",
    "        self.max_energy = max_energy\n",
    "        self.cooperator = cooperator\n",
    "        \n",
    "        self.played = True\n",
    "        self.newborn = True\n",
    "        \n",
    "        \n",
    "    def play(self):\n",
    "        \"\"\"\n",
    "        Return game action based on agent type.\n",
    "        All agents use either always-cooperate or always-defect strategy.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.cooperator:\n",
    "            return Action.COOPERATE\n",
    "        else:\n",
    "            return Action.DEFECT\n",
    "        \n",
    "        \n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Agent behaviour in a single timestep.\n",
    "        \"\"\"\n",
    "        \n",
    "        # don't step if created this turn\n",
    "        if self.newborn:\n",
    "            return\n",
    "\n",
    "        neighbors = self.model.grid.get_neighbors(self.pos, moore=True)\n",
    "        # discard neighbors who have already played a game in this step\n",
    "        opponents = list(filter(\n",
    "            lambda a: not a.played,\n",
    "            neighbors))\n",
    "        # discard remembered defectors\n",
    "        opponents = list(filter(\n",
    "            lambda a: not self.memory.contains(a.unique_id) and not a.memory.contains(self.unique_id),\n",
    "            opponents))\n",
    "\n",
    "        # find opponent\n",
    "        if opponents:\n",
    "            opponent = self.random.choice(opponents)\n",
    "\n",
    "            # play pd game\n",
    "            if not self.played:\n",
    "\n",
    "                a = self.play()\n",
    "                b = opponent.play()\n",
    "\n",
    "                R, T, S, P = self.model.R, self.model.T, self.model.S, self.model.P\n",
    "\n",
    "                if   a == Action.COOPERATE and b == Action.COOPERATE:\n",
    "                    self.energy     += R\n",
    "                    opponent.energy += R\n",
    "                    \n",
    "                elif a == Action.COOPERATE and b == Action.DEFECT:\n",
    "                    self.energy     += S\n",
    "                    opponent.energy += T\n",
    "\n",
    "                    # remember betrayal\n",
    "                    self.memory.add(opponent.unique_id)\n",
    "                    \n",
    "                elif a == Action.DEFECT    and b == Action.COOPERATE:\n",
    "                    self.energy     += T\n",
    "                    opponent.energy += S\n",
    "\n",
    "                    # remember betrayal\n",
    "                    opponent.memory.add(self.unique_id)\n",
    "                    \n",
    "                elif a == Action.DEFECT    and b == Action.DEFECT:\n",
    "                    self.energy     += P\n",
    "                    opponent.energy += P\n",
    "\n",
    "                    # remember betrayals\n",
    "                    self.memory.add(opponent.unique_id)\n",
    "                    opponent.memory.add(self.unique_id)\n",
    "                    \n",
    "                self.energy = min(self.energy, self.max_energy)\n",
    "                opponent.energy = min(opponent.energy, opponent.max_energy)\n",
    "\n",
    "                self.played = True\n",
    "                opponent.played = True\n",
    "\n",
    "            # reproduce\n",
    "            max_population = (self.model.grid.width * self.model.grid.height) / 2\n",
    "            if (    self.cooperator and self.model.last_cooperator_count < max_population) or \\\n",
    "               (not self.cooperator and self.model.last_defector_count   < max_population):\n",
    "\n",
    "                neighborhood = self.model.grid.get_neighborhood(self.pos, moore=True)\n",
    "                unoccupied = list(filter(\n",
    "                    lambda c: self.model.grid.is_cell_empty(c), \n",
    "                    neighborhood))\n",
    "\n",
    "                if self.energy >= (self.model.energy_to_reproduce * 2) and unoccupied:\n",
    "\n",
    "                    cell = self.random.choice(unoccupied)\n",
    "                    offspring = SmaldinoAgentWithMemory(self.model,\n",
    "                                                        energy=self.model.energy_to_reproduce,\n",
    "                                                        max_energy=self.max_energy,\n",
    "                                                        cooperator=self.cooperator,\n",
    "                                                        memory_size=self.memory.size)\n",
    "                    self.model.grid.position_agent(offspring, cell[0], cell[1])\n",
    "                    self.model.schedule.add(offspring)\n",
    "\n",
    "                    # update values for DataCollector\n",
    "                    self.model.agent_count += 1\n",
    "                    if self.cooperator:\n",
    "                        self.model.cooperator_count += 1\n",
    "                    else:\n",
    "                        self.model.defector_count += 1\n",
    "\n",
    "                    self.energy -= self.model.energy_to_reproduce\n",
    "\n",
    "\n",
    "        elif not self.played:\n",
    "            # attempt movement\n",
    "            neighborhood = self.model.grid.get_neighborhood(self.pos, moore=True)\n",
    "            unoccupied = list(filter(\n",
    "                lambda c: self.model.grid.is_cell_empty(c), \n",
    "                neighborhood))\n",
    "\n",
    "            if unoccupied:\n",
    "                cell = self.random.choice(unoccupied)\n",
    "                self.model.grid.move_agent(self, cell)\n",
    "\n",
    "\n",
    "        # energy deduction (cost of living)\n",
    "        self.energy -= self.model.living_cost\n",
    "        if self.energy <= 0:\n",
    "            # die\n",
    "            self.model.grid.remove_agent(self)\n",
    "            self.model.schedule.remove(self)\n",
    "            return\n",
    "            \n",
    "        # update values for DataCollector\n",
    "        self.model.agent_count += 1\n",
    "\n",
    "        if self.cooperator:\n",
    "            self.model.cooperator_count += 1\n",
    "        else:\n",
    "            self.model.defector_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-southwest",
   "metadata": {
    "id": "respiratory-praise"
   },
   "outputs": [],
   "source": [
    "class SPDModel(Model):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 R=3, T=5, S=-1, P=0,\n",
    "                 starting_agent_count=10,\n",
    "                 starting_energies=range(1,51),\n",
    "                 max_energy=150,\n",
    "                 energy_to_reproduce=50,\n",
    "                 living_cost=1,\n",
    "                 memory_size=0,\n",
    "                 grid_size=10,\n",
    "                 wrap=True):\n",
    "        \"\"\"\n",
    "        Smaldino's spatial prisonner's dilemma model\n",
    "        extended with limited memory\n",
    "        \n",
    "        Args:\n",
    "            R, T, S, P:            PD payoffs\n",
    "            starting_agent_count:  starting number of agents\n",
    "            starting_energies:     list of possible starting energies for agents (picked at random)\n",
    "            max_energy:            maximal energy an agent can hold\n",
    "            energy_to_reproduce:   energy required to reproduce\n",
    "            living_cost:           energy deducted at the end of each step\n",
    "            memory_size:           agent memory size\n",
    "            grid_size:             size length of square grid to use\n",
    "            wrap:                  whether to wrap grid (torus bounds)\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        self.schedule = RandomActivation(self)\n",
    "        self.grid = SingleGrid(grid_size, grid_size, torus=wrap)\n",
    "        \n",
    "        self.R = R\n",
    "        self.T = T\n",
    "        self.S = S\n",
    "        self.P = P\n",
    "        self.energy_to_reproduce = energy_to_reproduce\n",
    "        self.living_cost = living_cost\n",
    "        \n",
    "        # Setup agents\n",
    "        self.cooperator_count = 0\n",
    "        self.defector_count = 0\n",
    "\n",
    "        for i in range(starting_agent_count):\n",
    "            energy = self.random.choice(starting_energies)\n",
    "            cooperator = i%2 == 0\n",
    "            \n",
    "            if cooperator:\n",
    "                self.cooperator_count += 1\n",
    "            else:\n",
    "                self.defector_count += 1\n",
    "            \n",
    "            agent = SmaldinoAgentWithMemory(self, \n",
    "                                            energy,\n",
    "                                            max_energy=max_energy,\n",
    "                                            cooperator=cooperator,\n",
    "                                            memory_size=memory_size)\n",
    "        \n",
    "            cell = self.random.choice(list(self.grid.empties))\n",
    "\n",
    "            self.grid.position_agent(agent, cell[0], cell[1])\n",
    "            self.schedule.add(agent)\n",
    "        \n",
    "        self.agent_count = starting_agent_count\n",
    "        \n",
    "        # Init model\n",
    "        self.running = True\n",
    "        \n",
    "        self.datacollector = DataCollector(\n",
    "            {\n",
    "                \"agent_count\": \"agent_count\",\n",
    "                \"cooperator_count\": \"cooperator_count\",\n",
    "                \"defector_count\": \"defector_count\",\n",
    "            },\n",
    "        )\n",
    "        self.datacollector.collect(self)\n",
    "        \n",
    "        \n",
    "    def step(self):\n",
    "        \n",
    "        # setup for step\n",
    "        self.last_cooperator_count = self.cooperator_count\n",
    "        self.last_defector_count   = self.defector_count\n",
    "        \n",
    "        self.agent_count = 0\n",
    "        self.cooperator_count = 0\n",
    "        self.defector_count = 0\n",
    "\n",
    "        for a in self.schedule.agents:\n",
    "            a.played = False\n",
    "            a.newborn = False\n",
    "    \n",
    "        # step\n",
    "        self.schedule.step()\n",
    "        self.datacollector.collect(self)\n",
    "        \n",
    "        # stop the model if no agents are alive\n",
    "        if self.cooperator_count == 0 or self.defector_count == 0:\n",
    "            self.running = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-documentation",
   "metadata": {
    "id": "stable-estate"
   },
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-laugh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "maritime-begin",
    "outputId": "5e4f8ff0-1866-43ed-d157-4a632a3c2f72"
   },
   "outputs": [],
   "source": [
    "spd = SPDModel(R=3, T=5, S=-1, P=0,\n",
    "               starting_agent_count=64,\n",
    "               starting_energies=range(1,50),\n",
    "               max_energy=150,\n",
    "               energy_to_reproduce=50,\n",
    "               living_cost=1,\n",
    "               memory_size=5,\n",
    "               grid_size=20,\n",
    "               wrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while spd.running and i < 50000:\n",
    "    spd.step()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-washington",
   "metadata": {},
   "source": [
    "### Render visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value(cell):\n",
    "    if cell is None:\n",
    "        return 0\n",
    "    elif isinstance(cell, Agent):\n",
    "        if cell.cooperator:\n",
    "            return 2\n",
    "        else:\n",
    "            return 10\n",
    "    else:\n",
    "        raise Exception(\"Unidentified cell: {}\".format(cell))\n",
    "        \n",
    "hmap = hv.HoloMap(kdims='step')\n",
    "i = 0\n",
    "while spd.running and i < 100:\n",
    "    spd.step()\n",
    "    data = np.array([[value(c) for c in row] for row in spd.grid.grid])\n",
    "    hmap[i] = hv.Image(data, vdims=[hv.Dimension('State', range=(0,10))])\n",
    "    i += 1\n",
    "hmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-pepper",
   "metadata": {},
   "source": [
    "### Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-going",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "later-sharing",
    "outputId": "e2f9a606-8093-4323-8d10-1ab7f385ee25"
   },
   "outputs": [],
   "source": [
    "results = spd.datacollector.get_model_vars_dataframe()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "sns.lineplot(data=results[['cooperator_count', 'defector_count']], ax=ax)\n",
    "# ax.set_xlim(0, 1000)\n",
    "ax.set_ylim(0)\n",
    "ax.set_xlabel('step')\n",
    "ax.set_ylabel('number of agents of a type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_plot_export(fig, [ax], 'frequency_time_with_memory')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-shift",
   "metadata": {
    "id": "former-freeze"
   },
   "source": [
    "## Paramater sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-setting",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "blessed-disney",
    "outputId": "613aa169-0230-484f-99ea-0039fbb134fe"
   },
   "outputs": [],
   "source": [
    "variable_parameters = {\n",
    "    \"memory_size\": range(0, 4),\n",
    "}\n",
    "fixed_parameters = {\n",
    "    \"R\": 3,\n",
    "    \"T\": 5,\n",
    "    \"S\": -1,\n",
    "    \"P\": 0,\n",
    "    \"starting_agent_count\":  64,\n",
    "    \"starting_energies\":     range(1,50),\n",
    "    \"max_energy\":            150,\n",
    "    \"energy_to_reproduce\":   50,\n",
    "    \"living_cost\":           1,\n",
    "    \"grid_size\":             20,\n",
    "    \"wrap\":                  True,\n",
    "}\n",
    "\n",
    "iterations = 20\n",
    "max_steps = 50\n",
    "\n",
    "param_run = BatchRunnerMP(SPDModel,\n",
    "                          nr_processes=None,  # detect automatically\n",
    "                          variable_parameters=variable_parameters,\n",
    "                          fixed_parameters=fixed_parameters,\n",
    "                          iterations=iterations,\n",
    "                          max_steps=max_steps,\n",
    "                          model_reporters={\n",
    "                              \"agent_count\": lambda m: m.agent_count,\n",
    "                              \"cooperator_count\": lambda m: m.cooperator_count,\n",
    "                              \"defector_count\": lambda m: m.defector_count,\n",
    "                          })\n",
    "\n",
    "param_run.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-dryer",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "upset-light",
    "outputId": "324591e0-2d84-4f8d-f04c-33c54c6a61e7"
   },
   "outputs": [],
   "source": [
    "run_data = param_run.get_model_vars_dataframe()\n",
    "run_data['cooperator_frequency'] = (run_data['cooperator_count'] / run_data['agent_count'])\n",
    "run_data['defector_frequency']   = (run_data['defector_count']   / run_data['agent_count'])\n",
    "run_data = run_data.dropna()\n",
    "run_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-target",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "employed-football",
    "outputId": "9eeb4701-2abf-468e-f733-dacb1b9b1dcd"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1)\n",
    "sns.boxplot(x=\"memory_size\", y=\"cooperator_frequency\", data=run_data, ax=ax)\n",
    "ax.set_ylim(0, 1.0)\n",
    "ax.set_xlabel(\"Memory size\")\n",
    "ax.set_ylabel(\"Cooperator frequency\")\n",
    "ax.set_title(\"After {} steps\".format(max_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_plot_export(fig, [ax], 'cooperator_frequency_memory_{}steps'.format(max_steps))\n",
    "my_plot_export(fig, [ax], 'cooperator_frequency_memory_{}steps_large'.format(max_steps), fontsize=16)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SPD-smaldino.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
